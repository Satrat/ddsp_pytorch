{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98e50a-8b2e-4707-b207-526381c5c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from ddsp.core import extract_loudness, extract_pitch\n",
    "import numpy as np\n",
    "from os import makedirs, path\n",
    "import pretty_midi\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc70bb9-9573-4898-a37c-7510b7be83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHONEMES = ['sil', 'b','d','f','g','h','j','k','l','m','n','p','r','s','t','v','w','z','zh','ch','sh','th','dh','ng','y','ae','ei','e','ii','i','ai','a','ou','u','ao','uu','oi','au','eo','er','oo']\n",
    "PHONEME2ID={}\n",
    "for i,p in enumerate(PHONEMES):\n",
    "    PHONEME2ID[p] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1b46e-43b4-4f86-add4-2bc87b4d07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"export/ddsp_train_phonemes_fixed_pretrained.ts\"\n",
    "SAMPLE_RATE = 16000\n",
    "SIGNAL_LENGTH = 128000\n",
    "BLOCK_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e517bd-66c6-4458-b6a9-fe8a31c811f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d11795-7c37-4faa-bb7c-a48405f1ba33",
   "metadata": {},
   "source": [
    "## Resynthesize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5653e76-39d5-4d5b-822b-200c059f189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(\"../CSD/english/wav/en001a.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e410863b-664c-4e29-ba77-2dc06a996883",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = np.load(path.join(\"preprocessed\", \"signals.npy\"))\n",
    "pitches = np.load(path.join(\"preprocessed\", \"pitchs.npy\"))\n",
    "loudness = np.load(path.join(\"preprocessed\", \"loudness.npy\"))\n",
    "phonemes = np.load(path.join(\"preprocessed\", \"phonemes.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534862f8-d3d8-4d38-a400-b6d0859fdb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "p = pitches[idx].reshape((1,-1,1))\n",
    "l = loudness[idx].reshape((1,-1,1))\n",
    "pho = phonemes[idx].reshape((1,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8915ae-fc8d-4508-a9d8-7c118509267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb412853-edec-4d04-a903-71c4694584b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79274de1-f197-49d7-817d-a8a5ec94bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = model(torch.from_numpy(p), torch.from_numpy(l), torch.from_numpy(pho))\n",
    "audio_np = audio.detach().numpy().flatten()\n",
    "samples = audio_np.shape[0]\n",
    "length_sec = samples / SAMPLE_RATE\n",
    "print(\"{} samples, {} seconds\".format(samples, length_sec))\n",
    "ipd.Audio(audio_np, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698269b-949f-4c6b-8361-1f7200b0420b",
   "metadata": {},
   "source": [
    "## Timbre Transfer, unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6513a0-d78b-4ad0-8bd6-385ec97f7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FILE = \"audio.wav\"\n",
    "PHONEMES_FILE = \"phonemes.txt\"\n",
    "MIDI_FILE = \"test.mid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89e61c-bc83-4108-b14b-805a1eb57c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data,sr = librosa.load(TEST_FILE, sr=SAMPLE_RATE)\n",
    "ipd.Audio(full_data, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25661e-41df-4d68-8e77-371e66fa2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignPhonemesToMidi(phonemes_file, midi_file, audio_length):\n",
    "    with open(phonemes_file) as f:\n",
    "        lines = f.readlines()\n",
    "    phonemes_data = lines[0]\n",
    "    \n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    midi_notes = midi_data.instruments[0].notes\n",
    "    syllables = phonemes_data.split(\" \")\n",
    "    assert(len(midi_notes) == len(syllables))\n",
    "\n",
    "    #label_length = int(SIGNAL_LENGTH / BLOCK_SIZE)\n",
    "    label_length = audio_length\n",
    "    phoneme_labels = np.zeros(label_length)\n",
    "    tpb = BLOCK_SIZE * 1.0 / SAMPLE_RATE\n",
    "    cb = math.ceil(.05 / tpb)\n",
    "    for i, midi in enumerate(midi_notes):\n",
    "        start_frame = math.floor(midi.start * float(SAMPLE_RATE) / float(BLOCK_SIZE))\n",
    "        end_frame = math.ceil(midi.end * float(SAMPLE_RATE) / float(BLOCK_SIZE))\n",
    "\n",
    "        phonemes = syllables[i].split(\"_\")\n",
    "        N = len(phonemes)\n",
    "        duration = (end_frame - start_frame)\n",
    "        durations = np.zeros(N, dtype='int32')\n",
    "        for i, pho in enumerate(phonemes):\n",
    "            if(PHONEME2ID[pho] < PHONEME2ID['ae']):\n",
    "                durations[i] = cb\n",
    "        total_const_time = np.sum(durations)\n",
    "        n_const = total_const_time / cb\n",
    "        n_vowel = N - n_const\n",
    "        N_per_vowel = (duration - total_const_time) / n_vowel\n",
    "        for i, pho in enumerate(phonemes):\n",
    "            if(PHONEME2ID[pho] >= PHONEME2ID['ae']):\n",
    "                durations[i] = N_per_vowel\n",
    "        idx = start_frame\n",
    "        for i, pho in enumerate(phonemes):\n",
    "            phoneme_labels[idx:(idx + durations[i])] = PHONEME2ID[pho]\n",
    "            idx += durations[i]\n",
    "            \n",
    "    return phoneme_labels\n",
    "\n",
    "def constructLoudness(midi_file, audio_length, spacing=0.05, noise=0.2):\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    midi_notes = midi_data.instruments[0].notes\n",
    "    \n",
    "    times = np.zeros(len(midi_notes) * 2)\n",
    "    for i, midi in enumerate(midi_notes):\n",
    "        times[2 * i] = midi.start\n",
    "        times[2 * i + 1] = midi.end - spacing\n",
    "    time_samps = (times * SAMPLE_RATE / BLOCK_SIZE).astype('int32')\n",
    "    \n",
    "    onsets = np.random.default_rng().uniform(-3.0, -2.0, len(midi_notes))\n",
    "    offsets = np.random.default_rng().uniform(-6.0, -4.5, len(midi_notes))\n",
    "    loudness_pts = np.zeros(len(midi_notes) * 2)\n",
    "    for i in range(len(midi_notes)):\n",
    "        loudness_pts[2*i] = onsets[i]\n",
    "        loudness_pts[2*i + 1] = offsets[i]\n",
    "    \n",
    "    #size = np.max([SIGNAL_LENGTH // BLOCK_SIZE, time_samps[len(time_samps) - 1]])\n",
    "    #loudness = np.zeros(size)\n",
    "    loudness = np.zeros(audio_length)\n",
    "    for i in range(len(time_samps) - 1):\n",
    "        duration = time_samps[i+1] - time_samps[i]\n",
    "        loudness[time_samps[i]:time_samps[i+1]] = np.linspace(loudness_pts[i], loudness_pts[i + 1], num=duration)\n",
    "    loudness[time_samps[len(time_samps)-1]::] = loudness_pts[len(loudness_pts)-1]\n",
    "    \n",
    "    loudness = loudness + np.random.default_rng().uniform(-1.0 * noise, noise, len(loudness))\n",
    "    \n",
    "    return loudness\n",
    "\n",
    "def createVocals(test_file, phonemes_file, midi_file):\n",
    "    full_data,sr = librosa.load(test_file, sr=SAMPLE_RATE)\n",
    "    audio_length = len(full_data) // BLOCK_SIZE\n",
    "    phoneme_labels = alignPhonemesToMidi(phonemes_file, midi_file, audio_length)\n",
    "    loudness = constructLoudness(midi_file, audio_length)\n",
    "    pitch = extract_pitch(full_data, SAMPLE_RATE, BLOCK_SIZE)\n",
    "\n",
    "def createVocals(test_file, phonemes_file, midi_file):\n",
    "    full_data,sr = librosa.load(test_file, sr=SAMPLE_RATE)\n",
    "    audio_length = len(full_data) // BLOCK_SIZE\n",
    "    phoneme_labels = alignPhonemesToMidi(phonemes_file, midi_file, audio_length)\n",
    "    loudness = constructLoudness(midi_file, audio_length)\n",
    "    pitch = extract_pitch(full_data, SAMPLE_RATE, BLOCK_SIZE)\n",
    "    \n",
    "    segment_len = SIGNAL_LENGTH // BLOCK_SIZE\n",
    "    num_segments = math.ceil(audio_length * 1.0 / segment_len)\n",
    "    final_audio = np.array([])\n",
    "    for i in range(num_segments):\n",
    "        s = i * segment_len\n",
    "        e = i * segment_len + segment_len\n",
    "        p = pitch[s:e].reshape((1,-1,1)).astype('float32')\n",
    "        l = loudness[s:e].reshape((1,-1,1)).astype('float32')\n",
    "        pho = phoneme_labels[s:e].reshape((1,-1,1)).astype('int32')\n",
    "        audio_out = model(torch.from_numpy(p), torch.from_numpy(l), torch.from_numpy(pho))\n",
    "        final_audio = np.append(final_audio, audio_out.detach().numpy().flatten())\n",
    "\n",
    "    print(\"Generated {} samples, {} seconds\".format(final_audio.shape[0], final_audio.shape[0] / SAMPLE_RATE))\n",
    "    return final_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e4b6b-01df-4268-8bc9-951a5dd02974",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_length = len(full_data) // BLOCK_SIZE\n",
    "phoneme_labels = alignPhonemesToMidi(PHONEMES_FILE, MIDI_FILE, audio_length)\n",
    "loudness = constructLoudness(MIDI_FILE, audio_length)\n",
    "pitch = extract_pitch(full_data, SAMPLE_RATE, BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04622df-e9fc-46a9-9189-14984dbec77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90c899-447b-47bd-b422-0dd603e150de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loudness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc7b4ac-1325-4f75-ad64-d55c500a458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = createVocals(TEST_FILE, PHONEMES_FILE, MIDI_FILE)\n",
    "ipd.Audio(output, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42bd0e9-2fdf-40ef-84ce-779dd90d3cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
